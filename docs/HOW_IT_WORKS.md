# ğŸ“ Understanding the GPU Cluster Testing Tool

## Quick Answer: No Database!

**This tool does NOT use a database.** It generates synthetic data directly in GPU memory using `torch.randn()`. This is intentional - it's a **cluster validation tool**, not a real ML system.

---

## Architecture Overview

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              Container Image (12 GB)                        â”‚
â”‚  ghcr.io/ahmabboud/gpu_cluster_testing:latest             â”‚
â”‚                                                             â”‚
â”‚  Base: NVIDIA PyTorch 24.07                                â”‚
â”‚  â”œâ”€ CUDA 12.5 + cuDNN                                      â”‚
â”‚  â”œâ”€ Python 3.10 + PyTorch 2.4.0                            â”‚
â”‚  â””â”€ NCCL (GPU communication library)                       â”‚
â”‚                                                             â”‚
â”‚  /workspace/                                                â”‚
â”‚  â”œâ”€ src/                   (Training code)                 â”‚
â”‚  â”‚  â”œâ”€ train.py           (Main orchestrator)              â”‚
â”‚  â”‚  â”œâ”€ models/            (ResNet, Transformer)            â”‚
â”‚  â”‚  â””â”€ data_utils.py      (Synthetic data generator)       â”‚
â”‚  â”‚                                                          â”‚
â”‚  â”œâ”€ scripts/               (Automation)                    â”‚
â”‚  â”‚  â””â”€ entrypoint.sh      (Environment detector)           â”‚
â”‚  â”‚                                                          â”‚
â”‚  â””â”€ nccl-tests/            (Bandwidth tests)               â”‚
â”‚     â””â”€ build/all_reduce_perf                               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## How Data Works: NO DATABASE!

### Traditional ML Setup (Not Used Here)

```
Storage/Database          This Tool
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€          â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   ImageNet   â”‚          â”‚  GPU Memory  â”‚
â”‚   Database   â”‚    VS    â”‚  (VRAM)      â”‚
â”‚   (1 TB)     â”‚          â”‚              â”‚
â”‚              â”‚          â”‚ torch.randn()â”‚
â”‚ Load â†’ CPU   â”‚          â”‚ torch.randintâ”‚
â”‚  â†“           â”‚          â”‚              â”‚
â”‚ Preprocess   â”‚          â”‚ Instant!     â”‚
â”‚  â†“           â”‚          â”‚ No I/O!      â”‚
â”‚ GPU          â”‚          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
   Slow, Complex         Fast, Simple
```

### Synthetic Data Generation

```python
# src/data_utils.py - The "database" is this simple function!

def generate_synthetic_batch(batch_size, num_channels, height, width, 
                            num_classes, device):
    """Generate random data DIRECTLY in GPU memory"""
    
    # Create random images (RGB, 224x224)
    images = torch.randn(
        batch_size, num_channels, height, width,
        device=device,  # â† Created directly on GPU!
        dtype=torch.float32
    )
    
    # Create random labels (0-999 for ImageNet-style)
    labels = torch.randint(
        0, num_classes,
        (batch_size,),
        device=device,  # â† Created directly on GPU!
        dtype=torch.long
    )
    
    return images, labels

# That's it! No database, no files, no network I/O
```

**Why This Works**:
- Neural networks don't know if data is "real" or random
- GPU compute is identical
- NCCL communication is identical
- Network bandwidth testing works the same
- We're testing **infrastructure**, not model accuracy

---

## Complete Execution Flow

### Step-by-Step: What Happens When You Run a Test

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Step 1: Start Container                                    â”‚
â”‚                                                             â”‚
â”‚ $ docker run --gpus all --rm \                             â”‚
â”‚     cr.eu-north1.../gpu_cluster_testing:latest \           â”‚
â”‚     --model resnet50 --batch-size 64                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â”‚
                   â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Step 2: entrypoint.sh Executes                             â”‚
â”‚                                                             â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚ â”‚ Detect Environment:                                 â”‚   â”‚
â”‚ â”‚ - Slurm? Check SLURM_PROCID                         â”‚   â”‚
â”‚ â”‚ - Kubernetes? Check KUBERNETES_SERVICE_HOST         â”‚   â”‚
â”‚ â”‚ - Bare metal? Use manual env vars                   â”‚   â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                             â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚ â”‚ Map Variables:                                      â”‚   â”‚
â”‚ â”‚ SLURM_PROCID    â†’ RANK                              â”‚   â”‚
â”‚ â”‚ SLURM_NTASKS    â†’ WORLD_SIZE                        â”‚   â”‚
â”‚ â”‚ SLURM_LOCALID   â†’ LOCAL_RANK                        â”‚   â”‚
â”‚ â”‚ SLURM_NODELIST  â†’ MASTER_ADDR (first node)         â”‚   â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                             â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚ â”‚ GPU Detection:                                      â”‚   â”‚
â”‚ â”‚ $ nvidia-smi                                        â”‚   â”‚
â”‚ â”‚ Found 8 Ã— NVIDIA H100 PCIe                          â”‚   â”‚
â”‚ â”‚ â†’ Set BACKEND=nccl                                  â”‚   â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                             â”‚
â”‚ Launch: python /workspace/src/train.py --model resnet50   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â”‚
                   â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Step 3: train.py - Initialize Distributed Training         â”‚
â”‚                                                             â”‚
â”‚ def setup_distributed():                                   â”‚
â”‚     rank = int(os.environ["RANK"])         # 0            â”‚
â”‚     world_size = int(os.environ["WORLD_SIZE"])  # 8       â”‚
â”‚     local_rank = int(os.environ["LOCAL_RANK"])  # 0-7     â”‚
â”‚                                                             â”‚
â”‚     # Initialize process group (connects all GPUs)         â”‚
â”‚     dist.init_process_group(                               â”‚
â”‚         backend="nccl",  # GPU communication               â”‚
â”‚         init_method="env://",                              â”‚
â”‚         world_size=8,     # 8 GPUs total                   â”‚
â”‚         rank=0            # This process's rank            â”‚
â”‚     )                                                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â”‚
                   â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Step 4: Create and Wrap Model                              â”‚
â”‚                                                             â”‚
â”‚ # Create model (25M parameters)                            â”‚
â”‚ model = ResNet50(num_classes=1000)                         â”‚
â”‚                                                             â”‚
â”‚ # Move to GPU                                              â”‚
â”‚ model = model.to(device)  # device = cuda:0                â”‚
â”‚                                                             â”‚
â”‚ # Wrap with DistributedDataParallel (DDP)                  â”‚
â”‚ model = DDP(model, device_ids=[local_rank])                â”‚
â”‚ # â†‘ This is MAGIC!                                         â”‚
â”‚ # DDP automatically syncs gradients via NCCL               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â”‚
                   â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Step 5: Training Loop (100 iterations)                     â”‚
â”‚                                                             â”‚
â”‚ for iteration in range(100):                               â”‚
â”‚                                                             â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
â”‚   â”‚ 5a. Generate Data (NO DATABASE!)               â”‚     â”‚
â”‚   â”‚                                                  â”‚     â”‚
â”‚   â”‚ images, labels = generate_synthetic_batch(      â”‚     â”‚
â”‚   â”‚     batch_size=64,                              â”‚     â”‚
â”‚   â”‚     num_channels=3,   # RGB                     â”‚     â”‚
â”‚   â”‚     height=224,                                 â”‚     â”‚
â”‚   â”‚     width=224,                                  â”‚     â”‚
â”‚   â”‚     num_classes=1000,                           â”‚     â”‚
â”‚   â”‚     device='cuda:0'   # Directly in GPU memory!â”‚     â”‚
â”‚   â”‚ )                                                â”‚     â”‚
â”‚   â”‚                                                  â”‚     â”‚
â”‚   â”‚ Shape: images = [64, 3, 224, 224]              â”‚     â”‚
â”‚   â”‚        labels = [64]                            â”‚     â”‚
â”‚   â”‚ Memory: ~150 MB in GPU VRAM                     â”‚     â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
â”‚                                                             â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
â”‚   â”‚ 5b. Forward Pass (GPU Compute)                 â”‚     â”‚
â”‚   â”‚                                                  â”‚     â”‚
â”‚   â”‚ output = model(images)                          â”‚     â”‚
â”‚   â”‚ # Runs convolutions, batch norms, ReLU, etc.   â”‚     â”‚
â”‚   â”‚ # Tests GPU compute performance                â”‚     â”‚
â”‚   â”‚                                                  â”‚     â”‚
â”‚   â”‚ Shape: output = [64, 1000]  (predictions)      â”‚     â”‚
â”‚   â”‚ Time: ~30 ms                                    â”‚     â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
â”‚                                                             â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
â”‚   â”‚ 5c. Compute Loss                               â”‚     â”‚
â”‚   â”‚                                                  â”‚     â”‚
â”‚   â”‚ loss = criterion(output, labels)                â”‚     â”‚
â”‚   â”‚ # CrossEntropyLoss                              â”‚     â”‚
â”‚   â”‚                                                  â”‚     â”‚
â”‚   â”‚ Time: <1 ms                                     â”‚     â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
â”‚                                                             â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
â”‚   â”‚ 5d. Backward Pass (Gradients + NCCL!)         â”‚     â”‚
â”‚   â”‚                                                  â”‚     â”‚
â”‚   â”‚ loss.backward()                                 â”‚     â”‚
â”‚   â”‚                                                  â”‚     â”‚
â”‚   â”‚ What happens:                                   â”‚     â”‚
â”‚   â”‚ 1. Compute gradients (GPU compute)             â”‚     â”‚
â”‚   â”‚    Time: ~25 ms                                 â”‚     â”‚
â”‚   â”‚                                                  â”‚     â”‚
â”‚   â”‚ 2. DDP triggers NCCL All-Reduce! â† CRITICAL    â”‚     â”‚
â”‚   â”‚    - Each GPU has gradients for 25M params     â”‚     â”‚
â”‚   â”‚    - All-Reduce averages across all 8 GPUs     â”‚     â”‚
â”‚   â”‚    - Uses NVLink (single node) or              â”‚     â”‚
â”‚   â”‚      InfiniBand (multi-node)                   â”‚     â”‚
â”‚   â”‚    - Tests network bandwidth!                  â”‚     â”‚
â”‚   â”‚    Time: ~5-10 ms (depends on network)         â”‚     â”‚
â”‚   â”‚                                                  â”‚     â”‚
â”‚   â”‚ 3. All GPUs now have synchronized gradients    â”‚     â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
â”‚                                                             â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
â”‚   â”‚ 5e. Update Weights                             â”‚     â”‚
â”‚   â”‚                                                  â”‚     â”‚
â”‚   â”‚ optimizer.step()                                â”‚     â”‚
â”‚   â”‚ # Update model parameters                       â”‚     â”‚
â”‚   â”‚                                                  â”‚     â”‚
â”‚   â”‚ Time: ~2 ms                                     â”‚     â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
â”‚                                                             â”‚
â”‚   Total iteration time: ~47 ms                             â”‚
â”‚   Throughput: 64 Ã— 8 GPUs / 0.047s = ~10,800 samples/sec  â”‚
â”‚                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â”‚
                   â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Step 6: Report Results                                     â”‚
â”‚                                                             â”‚
â”‚ {                                                           â”‚
â”‚   "model": "resnet50",                                     â”‚
â”‚   "world_size": 8,                                         â”‚
â”‚   "batch_size_per_gpu": 64,                                â”‚
â”‚   "global_batch_size": 512,                                â”‚
â”‚   "avg_step_time_ms": 47.2,                                â”‚
â”‚   "throughput_samples_per_second": 14234,                  â”‚
â”‚   "nccl_overhead_ms": 4.8,                                 â”‚
â”‚   "gpu_utilization_pct": 93.5,                             â”‚
â”‚   "backend": "nccl"                                        â”‚
â”‚ }                                                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## What Gets Tested

### 1. GPU Compute Performance âœ…

**Tested during**:
- Forward pass: Convolutions, matrix multiplications
- Backward pass: Gradient computation

**Metrics**:
- Samples per second
- GPU utilization (target: >90%)
- Step time

**Why synthetic data works**: GPU doesn't care if data is random or real - math is the same!

### 2. NCCL Communication âœ… (Most Important!)

**Tested during**:
- Gradient synchronization (All-Reduce operation)
- Multi-GPU coordination

**What it validates**:
- **Single node**: NVLink bandwidth between GPUs (~400 GB/s for H100)
- **Multi-node**: InfiniBand/Ethernet between servers (~200 GB/s for HDR IB)
- **Latency**: Communication overhead (<10ms is good)
- **Stability**: No NCCL errors during 100+ iterations

**This is the PRIMARY purpose** - validate the network!

### 3. Cluster Stability âœ…

**Tested during**:
- Sustained 100+ iteration run
- Continuous GPU load
- Continuous network traffic

**What it validates**:
- GPUs maintain clock speeds (no thermal throttling)
- Power delivery is stable
- Network doesn't have intermittent issues
- No OOM (out of memory) errors

---

## Multi-Node Example

### 4 Nodes Ã— 8 GPUs = 32 GPUs Total

```
Node 0 (Master)           Node 1                Node 2                Node 3
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ RANK 0-7     â”‚         â”‚ RANK 8-15    â”‚     â”‚ RANK 16-23   â”‚     â”‚ RANK 24-31   â”‚
â”‚              â”‚         â”‚              â”‚     â”‚              â”‚     â”‚              â”‚
â”‚ GPU 0-7      â”‚         â”‚ GPU 0-7      â”‚     â”‚ GPU 0-7      â”‚     â”‚ GPU 0-7      â”‚
â”‚              â”‚         â”‚              â”‚     â”‚              â”‚     â”‚              â”‚
â”‚ NVLink â†â†’    â”‚         â”‚ NVLink â†â†’    â”‚     â”‚ NVLink â†â†’    â”‚     â”‚ NVLink â†â†’    â”‚
â”‚ (400 GB/s)   â”‚         â”‚ (400 GB/s)   â”‚     â”‚ (400 GB/s)   â”‚     â”‚ (400 GB/s)   â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚                        â”‚                     â”‚                     â”‚
       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                â”‚    InfiniBand       â”‚
                                â”‚    (200 GB/s)       â”‚
                                â”‚                     â”‚
                          â”Œâ”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”
                          â”‚   All-Reduce across 32 GPUs     â”‚
                          â”‚   - Synchronize gradients        â”‚
                          â”‚   - Test cross-node network      â”‚
                          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**What happens during All-Reduce**:
1. Each GPU computes gradients locally (25M parameters Ã— 4 bytes = 100 MB)
2. NCCL performs All-Reduce:
   - Within node: Use NVLink (fast!)
   - Between nodes: Use InfiniBand (tests network!)
3. All 32 GPUs end up with averaged gradients
4. **This tests your InfiniBand fabric** - the whole point!

---

## The Image Explained

### What's Inside

```
ghcr.io/ahmabboud/gpu_cluster_testing:latest
â”‚
â”œâ”€â”€ Base: nvcr.io/nvidia/pytorch:24.07-py3
â”‚   â”œâ”€â”€ Ubuntu 22.04
â”‚   â”œâ”€â”€ CUDA 12.5 (GPU drivers, libraries)
â”‚   â”œâ”€â”€ cuDNN (optimized neural net ops)
â”‚   â”œâ”€â”€ Python 3.10
â”‚   â”œâ”€â”€ PyTorch 2.4.0 (with NCCL support)
â”‚   â””â”€â”€ NCCL 2.20+ (GPU communication)
â”‚
â”œâ”€â”€ System Tools (+200 MB)
â”‚   â”œâ”€â”€ Network diagnostics (ip, ping, netstat)
â”‚   â”œâ”€â”€ MPI (for NCCL tests)
â”‚   â””â”€â”€ Build tools (gcc, make)
â”‚
â”œâ”€â”€ NCCL Test Binaries (+50 MB)
â”‚   â””â”€â”€ /workspace/nccl-tests/build/
â”‚       â”œâ”€â”€ all_reduce_perf     (bandwidth test)
â”‚       â”œâ”€â”€ all_reduce_perf_mpi (multi-node test)
â”‚       â””â”€â”€ ... (other tests)
â”‚
â””â”€â”€ Application Code (+5 MB)
    â”œâ”€â”€ /workspace/src/
    â”‚   â”œâ”€â”€ train.py           (496 lines - main orchestrator)
    â”‚   â”œâ”€â”€ models/
    â”‚   â”‚   â”œâ”€â”€ resnet.py      (235 lines - ResNet-50)
    â”‚   â”‚   â””â”€â”€ transformer.py (270 lines - Transformer)
    â”‚   â”œâ”€â”€ data_utils.py      (148 lines - synthetic data!)
    â”‚   â””â”€â”€ dataset_loaders.py (329 lines - optional real data)
    â””â”€â”€ /workspace/scripts/
        â””â”€â”€ entrypoint.sh      (191 lines - environment detector)

Total Size: ~12 GB
```

### Why This Base Image?

**nvcr.io/nvidia/pytorch:24.07-py3**:
- Official NVIDIA image (tested and optimized)
- CUDA + PyTorch pre-configured
- NCCL pre-installed and working
- Saves us from dependency hell!

### What We Added

1. **Network diagnostics**: So you can debug connectivity issues
2. **NCCL test binaries**: For focused bandwidth testing
3. **Our training code**: The actual test logic
4. **entrypoint.sh**: Auto-detects Slurm/K8s/bare metal

---

## Key Design Decisions

### Why Synthetic Data?

| Approach | Pros | Cons |
|----------|------|------|
| **Real Data** | Realistic, tests I/O | Requires storage, network, setup |
| **Synthetic** âœ… | Zero setup, instant, portable | Not "real" ML |

**For cluster validation, synthetic is better because**:
- We're testing infrastructure, not models
- GPU compute is identical
- NCCL communication is identical
- Removes variables (storage speed, network latency to storage)
- Pure GPU + interconnect testing

### Why Two Test Modes?

**Full Training Tests** (20 minutes):
```python
# Realistic ML workload
model = ResNet50()
for i in range(100):
    data = generate_synthetic_batch()
    loss = model(data)
    loss.backward()  # â† Tests NCCL
```
- Tests complete stack
- Realistic resource usage
- Good for acceptance testing

**NCCL Bandwidth Tests** (5 minutes):
```bash
# Direct NCCL test
./all_reduce_perf -b 8K -e 8G
```
- Isolated network testing
- Quick feedback
- Good for debugging

Both complement each other!

---

## Common Questions

### Q: No database means no real ML training?
**A**: Correct! This is a **validation tool**, not a training system. Think of it like a stress test for your cluster.

### Q: How do you know the results are valid?
**A**: We compare against known benchmarks (H100: ~14k samples/sec, ~400 GB/s NVLink). If your cluster matches, it's good!

### Q: What if I want to use real data?
**A**: You can! Use `--data-mode cifar10` or `--data-mode imagenet`. But for cluster validation, synthetic is recommended.

### Q: Does this replace real ML training?
**A**: No! This validates the cluster. Once validated, run your real ML workloads.

### Q: What about storage performance testing?
**A**: Out of scope. This tests GPU + network only. Test storage separately.

---

## Summary

**The "Database"**: 
```python
torch.randn()  # That's it!
```

**The Image**:
- NVIDIA PyTorch base + our training code + NCCL tests
- ~12 GB, self-contained, works anywhere

**What It Tests**:
1. GPU compute (forward/backward pass)
2. NCCL communication (All-Reduce) â† **Most important!**
3. Cluster stability (sustained load)

**How It Works**:
1. Detect environment (Slurm/K8s/bare metal)
2. Initialize distributed training (connect all GPUs)
3. Generate data in GPU memory (no database!)
4. Train model (tests compute + NCCL)
5. Report performance metrics

**Why It's Effective**:
- Zero dependencies = works anywhere
- Synthetic data = tests what matters
- Self-contained = easy to deploy
- Fast = quick validation

This tool answers one question: **"Is this GPU cluster ready for production ML workloads?"**

The answer comes from GPU utilization, NCCL bandwidth, and stability over 100+ iterations - not from model accuracy!
