apiVersion: v1
kind: Pod
metadata:
  name: gpu-cluster-test-multi-gpu-single-node
  namespace: default
  labels:
    app: gpu-cluster-test
    mode: multi-gpu-single-node
spec:
  restartPolicy: Never
  containers:
  - name: test
    image: ghcr.io/ahmabboud/gpu_cluster_testing:latest
    imagePullPolicy: Always
    command: ["bash", "-lc"]
    args:
      - |
        set -euo pipefail
        if [ -d /opt/hpcx/ucx/lib ] && [ -d /opt/hpcx/ucc/lib ]; then
          export LD_LIBRARY_PATH="/opt/hpcx/ucx/lib:/opt/hpcx/ucc/lib:${LD_LIBRARY_PATH:-}"
        fi
        export NCCL_DEBUG=${NCCL_DEBUG:-INFO}
        export NCCL_SOCKET_IFNAME=${NCCL_SOCKET_IFNAME:-eth0}
        cd /workspace/src
        echo "Running torchrun (single-node)..."
        torchrun --standalone --nnodes=1 --nproc_per_node="${NPROC_PER_NODE}" \
          train.py --model resnet18 --batch-size 64 --warmup-iterations 10 --active-iterations 50 --data-mode synthetic
    env:
    # Change to 8 on an 8-GPU node (and update GPU requests/limits below)
    - name: NPROC_PER_NODE
      value: "2"
    resources:
      requests:
        nvidia.com/gpu: 2
      limits:
        nvidia.com/gpu: 2
    volumeMounts:
    - name: dshm
      mountPath: /dev/shm
  volumes:
  - name: dshm
    emptyDir:
      medium: Memory
      sizeLimit: 8Gi
